{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e7cff1-fc4e-47be-83c9-ded785be1eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-probability==0.16.0 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (0.16.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow-probability==0.16.0) (1.15.0)\n",
      "Requirement already satisfied: decorator in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow-probability==0.16.0) (5.1.0)\n",
      "Requirement already satisfied: dm-tree in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow-probability==0.16.0) (0.1.7)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow-probability==0.16.0) (1.22.3)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow-probability==0.16.0) (2.0.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow-probability==0.16.0) (0.4.0)\n",
      "Requirement already satisfied: absl-py in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow-probability==0.16.0) (0.15.0)\n",
      "Requirement already satisfied: tensorflow==2.8.0 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (2.8.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (0.4.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: numpy>=1.20 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (4.2.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (0.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (3.3.0)\n",
      "Requirement already satisfied: setuptools in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (58.0.4)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (14.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (3.18.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (1.41.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (1.12)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (0.26.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (1.12.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (2.10.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (2.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow==2.8.0) (1.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.0.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.0.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.1.1)\n",
      "Requirement already satisfied: tensorflow_datasets in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (4.6.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (2.26.0)\n",
      "Requirement already satisfied: toml in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: termcolor in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (4.62.3)\n",
      "Requirement already satisfied: numpy in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (1.22.3)\n",
      "Requirement already satisfied: dill in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (0.3.5)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (3.18.1)\n",
      "Requirement already satisfied: etils[epath] in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (0.6.0)\n",
      "Requirement already satisfied: six in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (1.8.0)\n",
      "Requirement already satisfied: absl-py in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (0.15.0)\n",
      "Requirement already satisfied: importlib-resources in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (5.8.0)\n",
      "Requirement already satisfied: promise in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/common/software/nersc/shasta2105/tensorflow/2.6.0/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2021.10.8)\n",
      "Requirement already satisfied: zipp in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from etils[epath]->tensorflow_datasets) (3.8.0)\n",
      "Requirement already satisfied: typing_extensions in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from etils[epath]->tensorflow_datasets) (4.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /global/u1/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow-probability==0.16.0 --user\n",
    "!pip install -U tensorflow==2.8.0 --user\n",
    "!pip install tensorflow_datasets --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31191128-7e58-41d7-a531-a3b2ecafebed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following have been reloaded with a version change:\n",
      "  1) cudnn/8.2.0 => cudnn/8.3.2     3) tensorflow/2.6.0 => tensorflow/2.9.0\n",
      "  2) gcc/10.3.0 => gcc/11.2.0\n",
      "\n",
      "\u001b[1;31mLmod has detected the following error: \u001b[0m The following module(s) are\n",
      "unknown: \"tensorflow_probability\"\n",
      "\n",
      "Please check the spelling or version number. Also try \"module spider ...\"\n",
      "It is also possible your cache file is out-of-date; it may help to try:\n",
      "  $ module --ignore-cache load \"tensorflow_probability\"\n",
      "\n",
      "Also make sure that all modulefiles written in TCL start with the string\n",
      "#%Module\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1;31mLmod has detected the following error: \u001b[0m The following module(s) are\n",
      "unknown: \"tensorflow_datasets\"\n",
      "\n",
      "Please check the spelling or version number. Also try \"module spider ...\"\n",
      "It is also possible your cache file is out-of-date; it may help to try:\n",
      "  $ module --ignore-cache load \"tensorflow_datasets\"\n",
      "\n",
      "Also make sure that all modulefiles written in TCL start with the string\n",
      "#%Module\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!module load tensorflow\n",
    "!module load tensorflow_probability\n",
    "!module load tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b8a86a-7c13-4d1a-a9ef-8aa304268b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os,re\n",
    "import sklearn.datasets as skd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import ffjord_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "465cd74d-39a5-4a7d-9509-0e3493809939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_ODE(keras.Model):\n",
    "    \"\"\"Multi-layer NN ode_fn.\"\"\"\n",
    "    def __init__(self, num_hidden, num_layers, num_output,num_cond=2,name='mlp_ode'):\n",
    "        super(MLP_ODE, self).__init__()\n",
    "        self._num_hidden = num_hidden\n",
    "        self._num_output = num_output\n",
    "        self._num_layers = num_layers\n",
    "        self._num_cond = num_cond\n",
    "        self._modules = []\n",
    "        \n",
    "        #Fully connected layers with tanh activation and linear output\n",
    "        self._modules.append(Input(shape=(1+self._num_output+self._num_cond))) #time is part of the inputs\n",
    "        for _ in range(self._num_layers - 1):\n",
    "            self._modules.append(layers.Dense(self._num_hidden,activation='tanh'))\n",
    "            \n",
    "        self._modules.append(layers.Dense(self._num_output,activation=None))\n",
    "        self._model = keras.Sequential(self._modules)\n",
    "\n",
    "        if self._num_cond > 1:\n",
    "            #In more dimensions, is useful to feed the conditional distributions after passing through an independent network model\n",
    "            self._cond_model = keras.Sequential(\n",
    "                [\n",
    "                    Input(shape=(self._num_cond)),\n",
    "                    layers.Dense(self._num_hidden,activation='relu'),\n",
    "                    layers.Dense(self._num_cond,activation=None),\n",
    "                ])\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, t, data,conditional_input=None):\n",
    "        if self._num_cond==1:\n",
    "            #No network for a single feature\n",
    "            cond_transform=tf.cast(conditional_input,dtype=tf.float32)\n",
    "        else:\n",
    "            cond_transform = self._cond_model(conditional_input)\n",
    "            \n",
    "        t = t*tf.ones([data.shape[0],1])\n",
    "        inputs = tf.concat([t, data,cond_transform], -1)\n",
    "        return self._model(inputs)\n",
    "\n",
    "def make_bijector_kwargs(bijector, name_to_kwargs):\n",
    "    #Hack to pass the conditional information through all the bijector layers\n",
    "    if hasattr(bijector, 'bijectors'):\n",
    "        return {b.name: make_bijector_kwargs(b, name_to_kwargs) for b in bijector.bijectors}\n",
    "    else:\n",
    "        for name_regex, kwargs in name_to_kwargs.items():\n",
    "            if re.match(name_regex, bijector.name):\n",
    "                return kwargs\n",
    "    return {}\n",
    "\n",
    "def save_model(model,name=\"ffjord\",checkpoint_dir = './checkpoints'):\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    model.save_weights('{}/{}'.format(checkpoint_dir,name,save_format='tf'))\n",
    "\n",
    "def load_model(model,name=\"ffjord\",checkpoint_dir = './checkpoints'):\n",
    "    model.load_weights('{}/{}'.format(checkpoint_dir,name,save_format='tf')).expect_partial()\n",
    "    \n",
    "        \n",
    "class FFJORD(keras.Model):\n",
    "    def __init__(self, stacked_mlps, batch_size,num_output,trace_type='hutchinson',name='FFJORD'): #editing\n",
    "        super(FFJORD, self).__init__()\n",
    "        self._num_output=num_output\n",
    "        self._batch_size = batch_size \n",
    "        ode_solve_fn = tfp.math.ode.DormandPrince(atol=1e-5).solve\n",
    "        #Gaussian noise to trace solver\n",
    "        if trace_type=='hutchinson':\n",
    "            trace_augmentation_fn = ffjord_terms.trace_jacobian_hutchinson\n",
    "        elif trace_type == 'exact':\n",
    "            trace_augmentation_fn = ffjord_terms.trace_jacobian_exact\n",
    "        else:\n",
    "            raise Exception(\"Invalid trace estimator\")\n",
    "        \n",
    "        \n",
    "        self.bijectors = []\n",
    "        for imlp,mlp in enumerate(stacked_mlps):\n",
    "            ffjord = ffjord_terms.FFJORD(\n",
    "                state_time_derivative_fn=mlp,\n",
    "                ode_solve_fn=ode_solve_fn,\n",
    "                trace_augmentation_fn=trace_augmentation_fn,\n",
    "                name='bijector{}'.format(imlp), #Bijectors need to be names to receive conditional inputs\n",
    "                jacobian_factor = 0.1,\n",
    "                kinetic_factor = 0.3\n",
    "            )\n",
    "            self.bijectors.append(ffjord)\n",
    "\n",
    "        #Reverse the bijector order\n",
    "        self.chain = tfb.Chain(list(reversed(self.bijectors)))\n",
    "\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        #Determine the base distribution... may need to be switched to 1D normal, not sure\n",
    "        self.base_distribution = tfp.distributions.MultivariateNormalDiag(\n",
    "            loc=self._num_output*[0.0], scale_diag=self._num_output*[1.0]\n",
    "        )\n",
    "        \n",
    "        self.flow=self.Transform()\n",
    "        self._variables = self.flow.variables\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"List of the model's metrics.\n",
    "        We make sure the loss tracker is listed as part of `model.metrics`\n",
    "        so that `fit()` and `evaluate()` are able to `reset()` the loss tracker\n",
    "        at the start of each epoch and at the start of an `evaluate()` call.\n",
    "        \"\"\"\n",
    "        return [self.loss_tracker]\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, inputs, conditional_input=None):\n",
    "        kwargs = make_bijector_kwargs(self.flow.bijector,{'bijector.': {'conditional_input':conditional_input }})\n",
    "        return self.flow.bijector.forward(inputs,**kwargs)\n",
    "        \n",
    "            \n",
    "    def Transform(self):        \n",
    "        return tfd.TransformedDistribution(distribution=self.base_distribution, bijector=self.chain)\n",
    "\n",
    "    \n",
    "    @tf.function\n",
    "    def log_loss(self,_x,_c):\n",
    "        loss = -tf.reduce_mean(self.flow.log_prob(\n",
    "            _x,\n",
    "            bijector_kwargs=make_bijector_kwargs(\n",
    "                self.flow.bijector, {'bijector.': {'conditional_input': _c}})                                      \n",
    "        ))\n",
    "        \n",
    "        regularization_loss = tf.zeros_like(_x)\n",
    "        stacked = len(self.bijectors)\n",
    "        current_positions = _x\n",
    "        \n",
    "        for i in range(stacked):\n",
    "            index = stacked - 1 - i\n",
    "            kwargs = bijector_kwargs=make_bijector_kwargs(self.bijectors[index], {'bijector.': {'conditional_input': _c}})\n",
    "            current_positions, current_loss = self.bijectors[index]._regularization_loss(current_positions, **kwargs)\n",
    "            regularization_loss = regularization_loss + current_loss\n",
    "        \n",
    "        loss = loss + regularization_loss\n",
    "        \n",
    "        return loss    \n",
    "    \n",
    "    @tf.function\n",
    "    def conditional_prob(self,_x,_c):\n",
    "        prob = self.flow.prob(\n",
    "            _x,\n",
    "            bijector_kwargs=make_bijector_kwargs(\n",
    "                self.flow.bijector, {'bijector.': {'conditional_input': _c}})                                      \n",
    "        )\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    \n",
    "    @tf.function()\n",
    "    def train_step(self, values):\n",
    "        #Full shape needs to be given when using tf.dataset\n",
    "        data = values[:self._batch_size,:self._num_output]\n",
    "        cond = values[:self._batch_size,self._num_output:]\n",
    "        data.set_shape((self._batch_size,self._num_output))\n",
    "        cond.set_shape((self._batch_size,cond.shape[1]))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.log_loss(data,cond) \n",
    "            \n",
    "        g = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(g, self.trainable_variables))\n",
    "        self.loss_tracker.update_state(loss)\n",
    "\n",
    "        return {\"loss\": self.loss_tracker.result()}\n",
    "    \n",
    "    @tf.function\n",
    "    def test_step(self, values):\n",
    "        data = values[:self._batch_size,:self._num_output]\n",
    "        cond = values[:self._batch_size,self._num_output:]\n",
    "        data.set_shape((self._batch_size,self._num_output))\n",
    "        cond.set_shape((self._batch_size,cond.shape[1]))\n",
    "        \n",
    "        loss = self.log_loss(data,cond)\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        return {\"loss\": self.loss_tracker.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5252a94f-b8b9-4a86-9b86-91fb577004f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 10:22:04.497662: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-16 10:22:06.155704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38419 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "2022-06-16 10:22:06.156364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38419 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "2022-06-16 10:22:06.156979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38419 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n",
      "2022-06-16 10:22:06.157613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38419 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n",
      "2022-06-16 10:22:08.118073: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From /global/homes/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages/tensorflow_probability/python/math/ode/base.py:455: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/homes/c/csfuria/.local/perlmutter/tensorflow2.6.0/lib/python3.8/site-packages/tensorflow_probability/python/math/ode/base.py:455: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.while_loop(c, b, vars, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n",
      "2022-06-16 10:22:37.437429: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/235 [..............................] - ETA: 28:11 - loss: 3718.6479"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    LR = 5e-3\n",
    "    NUM_EPOCHS = 50\n",
    "    STACKED_FFJORDS = 1 #Number of stacked transformations\n",
    "    NUM_LAYERS = 4 #Hiddden layers per bijector\n",
    "    NUM_OUTPUT = 28*28 #Output dimension\n",
    "    NUM_HIDDEN = 4*NUM_OUTPUT #Hidden layer node size\n",
    "    NUM_COND = 1 #Number of conditional dimensions\n",
    "    BATCH_SIZE = 256 \n",
    "    \n",
    "    #MNIST data\n",
    "    ds_train, ds_info = tfds.load(\n",
    "        'mnist',\n",
    "        split='train',\n",
    "        shuffle_files=True,\n",
    "        as_supervised=True,\n",
    "        with_info=True\n",
    "    )\n",
    "    \n",
    "    def normalize_img(image, label):\n",
    "      \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "      return tf.reshape(tf.cast(image, tf.float32) / 255., [-1]), label\n",
    "\n",
    "    ds_train = ds_train.map(\n",
    "        normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds_train = ds_train.cache()\n",
    "    ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "    ds_train = ds_train.batch(BATCH_SIZE)\n",
    "    ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    ds_numpy = tfds.as_numpy(ds_train)\n",
    "    samples = np.concatenate([x for x, y in ds_numpy], axis=0)\n",
    "    conditions = np.concatenate([y for x, y in ds_numpy], axis=0)\n",
    "    conditions = np.reshape(conditions, [-1, 1]).astype(np.float32)\n",
    "    samples = np.concatenate([samples,conditions],-1)\n",
    "    \n",
    "    #Stack of bijectors \n",
    "    stacked_mlps = []\n",
    "    for _ in range(STACKED_FFJORDS):\n",
    "        mlp_model = MLP_ODE(NUM_HIDDEN, NUM_LAYERS, NUM_OUTPUT,NUM_COND)\n",
    "        stacked_mlps.append(mlp_model)\n",
    "\n",
    "    #Create the model\n",
    "    model = FFJORD(stacked_mlps,BATCH_SIZE,NUM_OUTPUT,trace_type='hutchinson')\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=LR))\n",
    "    \n",
    "    history = model.fit(\n",
    "        samples,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        verbose=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0124dd-f7de-4592-959b-4370e0b45927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model for future inference\n",
    "save_model(model)\n",
    "\n",
    "#Let's create a new model with the same architecture, but with the exact trace estimator\n",
    "new_model = FFJORD(stacked_mlps,BATCH_SIZE,NUM_OUTPUT,trace_type='exact',name='loaded_model')\n",
    "load_model(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5393c758-a509-4b44-81f7-2999197a15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "NSAMPLES = DATASET_SIZE * 10\n",
    "#Sample the learned distribution\n",
    "\n",
    "base_samples = new_model.base_distribution.sample(NSAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a3f27-f45a-4d14-879b-3c1535cc47bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = bijector_kwargs=make_bijector_kwargs(new_model.chain, {'bijector.': {'conditional_input': np.ones((NSAMPLES,1),dtype=np.float32)}})\n",
    "hopefully_works = new_model.call(base_samples, np.ones((NSAMPLES,1),dtype=np.float32))\n",
    "print(hopefully_works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d36b1-93a5-407a-9adf-872b4b2a5f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs to operation AddN of type AddN must have the same size and shape.  Input 0: [10,1] != input 1: [1000,1] [Op:AddN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ddd06-4724-4f3b-a87b-2cd006a7b131",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = -1\n",
    "current_positions = tf.convert_to_tensor([base_samples])\n",
    "all_positions = current_positions\n",
    "step_size = 0.05\n",
    "\n",
    "for i in range(STACKED_FFJORDS):\n",
    "    index = i\n",
    "    kwargs = bijector_kwargs=make_bijector_kwargs(model.bijectors[index], {'bijector.': {'conditional_input': np.ones((NSAMPLES,1),dtype=np.float32)}})\n",
    "    current_positions = model.bijectors[index]._forward_timesteps(current_positions, step_size, **kwargs)\n",
    "    all_positions = tf.concat([all_positions, current_positions], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd945e15-c8c1-44f6-9517-dd0a40a76daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_positions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd697055-8a27-4c8b-aaa1-c840bce93f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(current_positions[-1].numpy(), bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212cf7a-54b1-4f42-a5aa-75278691c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(STACKED_FFJORDS * (1 / step_size) + 1)\n",
    "y = np.repeat(x, NSAMPLES)\n",
    "all_positions = np.reshape(all_positions, [-1])\n",
    "num_steps = STACKED_FFJORDS * (1 / step_size) + 1\n",
    "print(np.size(y))\n",
    "print(np.size(all_positions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2b318-8c66-4c43-a03b-b120d04cac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "plt.hist2d(all_positions, y, bins=int(num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e1bb7-42f2-4cbb-abab-f43a01e3a0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(base_samples.numpy(), bins='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484aaaac-ce09-40e7-83cc-ff6012f5d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(samples[:,0], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3656de78-192f-492d-81b3-308ebf480b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.chain.bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f535b2-ac8e-47e2-b25a-584b098a1001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.6.0",
   "language": "python",
   "name": "tensorflow-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
